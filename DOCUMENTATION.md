# Home Lab Documentation



## Kali Attack VM
** RAM:  2GB
** Cores: 2
** Storage:  32GB  (13GB available)
hostname:  
domain:  kali


Let’s install the ‘Attack Machine’. This is where you’ll be simulating Red team attacks on your home lab’s simulated network.

The host machine MacOS m1 chip’s ARM architecture is best used with UTM (to minimize compatibility issues and bugs), so you’ll need to download the Kali iso from the UTM gallery, which assures compatibility with your system. 

The default VM terminal window that opens when you initially boot with the Kali installation iso does not work. So you’ll need to go into the UTM settings for this VM instance, and add a new Configuration for ‘Serial’ connection, which gives you a second terminal window which operates much more smoothly. This window also provides additional perks that are not normally afforded to Virtual Machines, such as access between your Local Host Machine and your Virtual Machine’s clipboard.

A large issue is that the installer constantly glitches and prevents the installation from proceeding further. This glitch usually happens right after setting the password. Proceeding after this would mean the installation goes through.
If there are too many glitches, you might want to restart your computer.
If this doesn’t do anything, destroy the UTM Virtual Machine instance, and create a new one from which to begin the install.
And eventually the installation will be successful.
** RAM:  2GB
** Cores: 2
** Storage:  32GB  (15GB available)

If the 2GB of RAM and 2 Cores are not enough, you can easily change it through UTM. 
You might not be able to change the amount of hard disk space since it needs to be formatted (essentially destroying the current machine), so the extra 15GB of free disk space (after the OS takes up the rest) should be enough to hold the applications and related data such as logs, etc. that you’ll be using on the Attack Machine.


Ubuntu Desktop for Wazuh Manager/Indexer/Dashboard
Minimum requirements:  2GB RAM and 2vCPU
Recommended:  4GB RAM and 8CPU core
** RAM:  2GB
** Cores:  2
** Disk space:  30GB  -  6.1 GB free after installation
enp0s1  DHCPv4:  192.168.64.23/24


## Wazuh
Spin up the dedicated Ubuntu server VM.
First, run apt update and apt upgrade to be sure dependencies are current.
You will install the Wazuh Indexer, Server, and Dashboard all on the same node, the Ubuntu Desktop VM.
You will install the agent on the Metasploitable Vulnerable Machine.

Install Ubuntu Desktop
Because we’re using UTM on an m1 chip, Ubuntu Desktop is not supported. So upgrade your Ubuntu Server to an Ubuntu Desktop (GNOME). 

You’ll need this in order to run Wazuh Dashboard.

Run the following command to install packages and dependencies:
$ sudo apt install ubuntu-gnome-desktop

After the installation, reboot the Ubuntu VM:
$ sudo reboot

It should restart, and display the window for the Graphical Desktop.
Login with your password.

Unfortunately, the Wazuh installation wizard does not support the ARM 64-bit architecture. It will give an error message if you download and open it.

So you’ll have to do everything manually.

Installing the Wazuh Indexer
According to Wazuh documentation, “Wazuh indexer is a highly scalable, full-text search and analytics engine. This Wazuh central component indexes and stores alerts generated by the Wazuh server and provides near real-time data search and analytics capabilities.”
“It’s a highly scalable full-text search engine and offers advanced security, alerting, index management, deep performance analysis, and several other features.”
The Wazuh “indexer” is the component responsible for receiving and indexing data from Wazuh agents. It’s a part of the Wazuh architecture that helps manage and index data collected from various sources, including logs, events, and alerts generated by Wazuh agents.
The installation process is divided into 3 stages:
Certificates creation
Nodes installation
Cluster initialization

Certificates Creation
First create and change directory into a folder to work from during the installation (from Home directory):
$ mkdir wazuh_files
$ cd wazuh_files

Install nano text editor (you’ll need to modify certain files)
$ sudo apt install nano

Generating the SSL certificates
Download the  ‘wazuh-certs-tool.sh’ script and the  ‘config.yml’  configuration file. 
This creates the certificates that encrypt communications between the Wazuh central components (you’ll need them to use any of the components):
$ curl -sO https://packages.wazuh.com/4.7/wazuh-certs-tool.sh
$ curl -sO https://packages.wazuh.com/4.7/config.yml

Check the current directory. You should see the two files you’ve just downloaded:
$ ls

Edit ./config.yml and replace the node names and IP values with the corresponding names and IP addresses. You need to do this for any Wazuh server, Wazuh indexer, and Wazuh dashboard nodes. Add as many node fields as needed.

Edit  ‘config.yml’
Replace the node names and IP values with the corresponding names and IP addresses. You need to do this for components: Wazuh server, Wazuh indexer, and Wazuh dashboard nodes. Add as many node fields as needed. 
$ nano config.yml

If you need to find out the machine’s IP address, run this command. The interface will probably be listed as enp0s1:
$ ip addr

Since we’re using this machine as the Indexer, Manager, and Dashboard, we’ll be storing the same IP in these three fields:

config.yml
-----------
nodes:
  # Wazuh indexer nodes
  indexer:
    - name: node-1
      ip: "<your_ip_here>"
  
  # Wazuh server nodes
    - name: wazuh-1
      ip: "<your_ip_here>"
  # Wazuh dashboard nodes
  dashboard:
    - name: dashboard
      ip: "<your_ip_here>"
----------
NOTE:  you will return to this step to install Wazuh on any other nodes. You’ll be adding the Metasploitable’s IP here later as a node.

Create the certificates using the downloaded wazu-certs-tool script:
$ bash ./wazuh-certs-tool.sh -A

There should now be a directory called  ‘wazuh-certificates’:
$ ls

Compress all the necessary files:
$ tar -cvf ./wazuh-certificates.tar -C ./wazuh-certificates/ .
**This command creates a new tar archive file named  ‘wazuh-certificates.tar’, containing all files and directories within the  ‘wazuh-certificates/‘  directory while showing the progress of archiving. The -c flag creates the archive;  -v is verbose mode, shows the progress of archiving files;  -f specifies the name of the archive file to create.

You should now have a new compressed .tar file:
$ ls

Remove the cert directory after you have compressed the files:
$ rm -rf ./wazuh-certificates

NOTE:
Since this machine is serving as the Wazuh indexer, server, and dashboard, you won't need to copy the  ‘wazuh-certificates.tar’  file to other nodes because all the Wazuh components are consolidated on this single machine. Later, you’ll be copying the  certificates  file to any new nodes (Metasploitable)

Nodes Installation
Install package dependencies if missing:
$ sudo apt-get install debconf adduser procps

Adding the Wazuh repository
NOTE:  you’ll be adding a GPG key before adding the repository itself. This GPG key helps in verifying the authenticity of the packages retrieved from the Wazuh repository.
A GPG key, which stands for GNU Privacy Guard key, is a cryptographic key used for encrypting and decrypting data, as well as verifying the authenticity of digital signatures.
Install the following packages if missing:
$ sudo apt-get install gnupg apt-transport-https
NOTE:  the above command installs two packages:  gnupg  and  apt-tansport-https
GnuPG  provides functionalities like encryption, decryption, digital signatures, and key management.
apt-transport-https  is a package that enables the Advanced Package Tool (apt) to handle repositories accessed over HTTPS. It allows apt to fetch packages securely from repositories that use the HTTPS protocol.

Install the GPG key:
$ sudo sh -c "curl -s https://packages.wazuh.com/key/GPG-KEY-WAZUH | gpg --no-default-keyring --keyring gnupg-ring:/usr/share/keyrings/wazuh.gpg --import && chmod 644 /usr/share/keyrings/wazuh.gpg"

NOTE:  In the above command, you are running many commands with pipes, where the output of one command serves as input for the next. 
Running ‘sudo’ with ‘bash -c’ gives you sudo elevated privileges to every command encased within the double quotes.  
Alternatively, you can add sudo in front of any command that needs permissions, right after the pipe.

Add the repository:
$ sudo sh -c 'echo "deb [signed-by=/usr/share/keyrings/wazuh.gpg] https://packages.wazuh.com/4.x/apt/ stable main" >> /etc/apt/sources.list.d/wazuh.list'

NOTE:  You won’t get a message in terminal after running the command. You can see where the repository was added at the end of the command.

Update the package index to ensure that your system is aware of the available packages in the new repository:
$ sudo apt update

Check if the repository was added:
$ cat /etc/apt/sources.list.d/wazuh.list

Verify that the packages from Wazuh are available even more:
$ apt-cache search wazuh

Installing the Wazuh Indexer
Install the Wazuh indexer package:
$ sudo apt-get -y install wazuh-indexer


***************************************

Error  (perhaps an issue with the Wazuh repository)
I needed to stop here.
After following step-by-step keys, I ended up getting this error after this command:
$ sudo apt-get -y install wazuh-indexer

Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
E: Unable to locate package wazuh-indexer

I tried everything I could 
Google
chatGPT
finding out what each command does
checked that every command was executed properly
checked that everything exists
Found the issue on GitHub somebody else had posted. It was not resolved.

Then tried visiting the website in the contents of the line defining the Wazuh repository:
$ cat /etc/apt/sources.list.d/wazuh.list 
> deb [signed-by=/usr/share/keyrings/wazuh.gpg] https://packages.wazuh.com/4.x/apt/ stable main

In browser address bar:
`https://packages.wazuh.com/4.x/apt/`

The web page displays the following error:
<Error>
<Code>NoSuchKey</Code>
	<Message>The specified key does not exist.</Message>
	<Key>4.x/apt/</Key>
	<RequestId>GHA9G9Z1ERBGASCF</RequestId>
	<HostId>g90HCwIzx5GCblithEXVS2ZKpbxpcfuzpTxIuWs6/OJY6Hz37+Rfu/TgXHrSXhzfPxo7Q8TKnb4=</HostId>
</Error>
It’s indicating that the key:  4.x/apt/    ... does not exist. 


******************************************

Add the Wazuh repository

Install the following packages:
$ apt-get install gnupg apt-transport-https

A GPG key, which stands for GNU Privacy Guard key, is a cryptographic key used for encrypting and decrypting data, as well as verifying the authenticity of digital signatures.

Install the GPG key:
$ sudo bash -c 'curl -s https://packages.wazuh.com/key/GPG-KEY-WAZUH | gpg --no-default-keyring --keyring gnupg-ring:/usr/share/keyrings/wazuh.gpg --import && chmod 644 /usr/share/keyrings/wazuh.gpg'

NOTE:  In the above command, you are running many commands with pipes, where the output of one command serves as input for the next. 
Running ‘sudo’ with ‘bash -c’ gives you sudo elevated privileges to every command encased within the single quotes.

Add the repository:
$ sudo bash -c 'echo "deb [signed-by=/usr/share/keyrings/wazuh.gpg] https://packages.wazuh.com/4.x/apt/ stable main" | tee -a /etc/apt/sources.list.d/wazuh.list'

You can check if the above command worked by viewing the contents of the repository file you added:
$ cat  /etc/apt/sources.list.d/wazuh.list

Update the packages information:
$ sudo apt update

Installing the Wazuh manager

Install the Wazuh manager package:
$ sudo apt -y install wazuh-manager

Enable and start the Wazuh manager service:
If you notice the following messages in the output: 
> Processing triggers for libc-bin (2.35-0ubuntu3.5) ...
> debconf: unable to initialize frontend: Dialog
> debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)
> debconf: falling back to frontend: Readline
...nothing is wrong. The messages refer to the Debian package configuration system. Because we are using the server CLI and not a Desktop interface, it’s informing us of the absence of a ‘front-end dialog’, so it’s falling back to a text-based front-end called ‘readline’.

Enable and start the Wazuh manager service with these 3 commands, separately:
$ sudo systemctl daemon-reload
$ sudo systemctl enable wazuh-manager
$ sudo systemctl start wazuh-manager

Run the following command to verify the Wazuh manager status:
$ systemctl status wazuh-manager

It should display Wazuh’s active status, and relevant information about the process:
> wazuh-manager.service - Wazuh manager
> Loaded: loaded (/lib/systemd/system/wazuh-manager.service; enabled; vendor preset: enabled)
> Active: active (running) since Fri 2024-01-05 16:51:15 UTC; 12s ago
> Process: 59773 ExecStart=/usr/bin/env /var/ossec/bin/wazuh-control start (code=exited, status=0/SUCCESS)
> Tasks: 119 (limit: 2191)
> Memory: 342.2M
> CPU: 12.550s
> CGroup: /system.slice/wazuh-manager.service

Before installing Filebeat, check that the ‘filebeat’ package is available in the repositories that your system is currently configured to use:
$ ls /etc/apt/sources.list.d/

If it’s not listed amongst the directory’s contents, add it.
Wazuh is built from a few smaller applications: Elasticsearch, Logstash, and Kibana (known as the ELK stack)
Filebeat is a lightweight and flexible open-source log shipper and forwarder developed by Elastic. 

Adding Filebeat Repository
First, download the Elastic GPG key and add it to the APT keyring with the following command:
$ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -

Check that the GPG key is in your keyring:
$ sudo ls /usr/share/keyrings/

Save the repository definition to to your system’s sources list: /etc/apt/sources.list.d/elastic-8.x.list:
$ echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list

Installing Filebeat
Install Filebeat directly after apt update:
$ sudo apt update && sudo apt install filebeat

Configuring Filebeat
To configure Filebeat to run automatically during boot, run:
sudo systemctl enable filebeat

Download the preconfigured Filebeat configuration file:
$ sudo curl -so /etc/filebeat/filebeat.yml https://packages.wazuh.com/4.7/tpl/wazuh/filebeat/filebeat.yml

Edit the configuration file if needed:
$ sudo nano /etc/filebeat/filebeat.yml

NOTE: By default, in a basic installation of Wazuh, ElasticSearch might be running on the same server as your Wazuh manager. The case is the same for this documentation.
So the .yml will probably already be configured properly, with host configured as the loopback IP for your localhost 127.0.0.1, separated by a semicolon for the Elasticsearch default port :9200.

Create a Filebeat keystroke to securely store authentication credentials.
$ filebeat keystore create 

A keystore is a secure storage mechanism used by Filebeat to store sensitive configuration settings, such as credentials and other secure parameters, separately from the main configuration files.

Add the default username and password to the secrets keystore, separately:
$ echo "admin" | sudo filebeat keystore add username --stdin --force
$ echo "admin" | sudo filebeat keystore add password --stdin --force

This sets the username and password as admin in the keystore.
Download the alerts template for the Wazuh indexer:
$ sudo curl -so /etc/filebeat/wazuh-template.json https://raw.githubusercontent.com/wazuh/wazuh/v4.7.1/extensions/elasticsearch/7.x/wazuh-template.json

Allow read permissions to the  wazuh-template.json  file:
$ sudo chmod go+r /etc/filebeat/wazuh-template.json

The above command uses ‘go+r’, in which g = group permissions, o = others

Install the Wazuh module for Filebeat:
$ sudo curl -s https://packages.wazuh.com/4.x/filebeat/wazuh-filebeat-0.3.tar.gz | sudo tar -xvz -C /usr/share/filebeat/module

These two commands connected via pipe downloads the compressed gzip file, then extracts and places it into the specified directory.

The Wazuh module in Filebeat we’ve just installed is an integration that allows Filebeat to do several things:
Collect Logs and data generated by Wazuh components such as the Wazuh manager, agents, or other Wazuh modules. 
Process Data by parsing, formatting, and structuring the collected logs and data into a standardized format compatible with Elasticsearch or other outputs supported by Filebeat. Provides pre-defined configurations and mappings for different Wazuh log types, making it easier to ingest and analyze Wazuh data. 
Ship Logs and data to destinations such as Elasticsearch, Logstash, or directly to third-party systems for indexing, analysis, and visualization. Enables users to view, search, and analyze security-related events and logs in tools like Kibana (part of the Elk Stack) or other visualization platforms. 





## Linode
Let’s create a Linode server on the cloud to host our pfSense and Snort. Our traffic will be routed through this instance.

You can choose one of the more basic plans (given the small complimentary $100 budget constraint). This would likely have the capable resources to spare in case of a last minute decision to add more functionality to the server to use pfSense and Snort. 
The dedicated 4GB plan should be enough.

Give the instance a descriptive name, such as ‘pfSenseLinode’, for easy future reference. 
Give it the Root Password. Root is the default privilege given to you on the instance.
You can decide to give it a specific SSH Key, VLAN, Firewall, or any Add-ons. Although this can be done later.
After Creating the Linode Instance, navigate to the Linodes panel from the Dashboard. 
There will be a list with the newly created pfSense Linode Instance.
Click the menu on far right of the pfSense Linode Instance row and click off to allow changes to be implemented.
NOTE: When not using a server, it could be a good idea to turn it off for the purposes of reducing the attack surface of any potential vulnerabilities which could be exploited. 

Now you need to load and install the image for pfSense from the iso. 

First, navigate to the Storage panel.
Delete the default partitions which were created by Linode.
Linode gives a status update with the percentage of task remaining, as well as a modal to let you know when it’s succeeded.


Second, create two new partitions.
The first partition can be labeled ‘Installer’, with 2GB size. This is where you will load the image, meant to emulate a CD-ROM drive.
The second partition can be labeled ‘PFSENSE’, with the rest of the maximum storage allocated. This will be the meat of the server, which contains every piece of software and data.
Third, delete the old default configurations.
A Linode configuration profile will allow you to customize boot settings for the server. This includes mounted disks, kernels, and network interfaces. You will create new ones to handle the installation boot from the iso/img, and the boot to start the server after installation.

Fourth, create two new configurations.
The first configuration is for the Installer: 
Label as ‘Installer config’. 
They provide options for up to 3 types of Kernels (Upstream, Linode, or Custom-compiled). Change the Kernel to ‘Direct Disk’ since you don’t actually want to install a Linux Kernel. Instead, this will use MBR (Master Boot Record) of the primary disk to directly install the pfSense iso image. 
The Block Device Assignment option makes the disk devices in Linux accessible at start-up, by assigning them to the instance’s disks. Up to 8 disks can be assigned. Assign  PFSENSE  to be installed on the  ‘/dev/sda’  disk (which is the main disk), and the  Installer  goes on  ‘/dev/sdb’ (which is the swap disk).
The Root Device is used to set the primary disk device. Set it to  ‘/dev/sdb’,  since this configuration profile is meant to boot up the installer with pfSense iso.
Lastly, unchecked all of the Filesystem/Boot Helpers, except for  ‘Auto-configure networking’.
The second configuration is for PFSENSE:
Label as ‘PFSENSE config’
Kernel is Direct Disk
/dev/sda  (main disk)  is once again pfSense
/dev/sda  remains empty (you won’t be needing it for this configuration, since pfSense will already be installed)
The Root Device will of course be set to main  /dev/sda  disk, which will contain pfSense. This is the main profile which will normally boot up your system. Because of this, you want it to load  pfSense,  which is stored in  /dev/sda.
As done previously, uncheck everything minus  ‘Auto-configure networking’.
Before going into Rescue Mode, you’ll need to download the pfSense iso.
To do this, you might want to use the Attack Machine created above.


## Back at Kali Attack VM
Download the latest version of Community Edition, for AMD64 architecture because Linode provides you with a 64-bit CPU. 
Download it with the USB Memstick Installer because the format that you’ll want is ‘.img’. According to pfSense documentation, it is “meant to be written to a USB flash drive before use and includes an installer that installs pfSense software to the hard drive on your system. This is the preferred means of running pfSense software.” You’ll be handling the installation on the Linode instance by mimicking a flash drive. 
Choose ‘Serial’ for the console. There are two consoles available: VGA and Serial.
VGA is a console with monitor and keyboard. Your Linode instance does not have any of these.
Serial console uses serial/COM port to communicate with a serial client. This one is intended for systems that do not use monitor and keyboard. This is what you want.
This will overwrite the entire hard drive.

In order to get the pfSense.img file onto your Linode instance, you’ll create a Web Server on Digital Ocean to host your images for download, via cURL from the terminal. 


Digital Ocean Web Server Droplet
Web servers are primarily used to process and manage HTTP/HTTPS requests and responses from the client system.

Image:  Ubuntu 23.10 x64
Size:  1 vCPU  |  2GB / 50GB Disk  |  ($14/mo)
Region:  NYC3
IPv4 address:  167.99.114.141
IPv6:  disabled
Private IP:  10.108.0.2
Virtual Private Cloud (VPC):  default-nyc3 (this is a private network which provides a secure connection between DigitalOcean resources because it’s inaccessible from the public internet)

Generate a new SSH key on the Kali attack machine with internet connection 
cat the .pub file (which stands for public SSH file, as opposed to the private file which should never be shared). 
Then use this ssh key to access the Digital Ocean server.
ssh root@server_ip
If you decide to set up ssh key from the dashboard, it might give you an error:
root@server_ip: Permission denied (publickey)
For some reason, the SSH key authentication might fail when attempting to connect to the Droplet. 
I log back into your Ubuntu Server VM where you’ll generate the key, and cat it’s id_rsa.pub file where you generated the key, and copied the key.  Then nano the Droplet’s `authorized_keys` file where the keys to allow remote connectivity from a remote host gets stored. Manually delete the public key that you had previously added from the DigitalOcean dashboard, and paste the public key you have just copied from my client’s id_rsa.pub file. When a client attempts to connect via SSH without a password, it presents it’s public key to the server, and the server will then check the `authorized_keys` file line-by-line to see if any of its stored keys match the client’s public key.
Check for ssh access from your VM’s terminal, and it should work!
You will now use a simple Web Serving application like Nginx on your droplet. 
From your ubuntu vm’s cli, which is currently connected to the droplet via ssh, install Nginx:
apt install nginx
From your browser, verify the install by navigating to the Droplet’s IP address. 

## Transfer pfSense image to web server
Use your Kali attack vm to download the pfSense image, and then transfer that image to your Digital Ocean web server Droplet. You’ll do this through  ‘scp’ (Secure Copy Protocol). This allows us with a convenient protocol with which to copy files between a source and destination host in a secure process. This is great for situations where security, confidentiality, or integrity are crucial. The reason scp is secure is because it leverages SSH as it’s underlying protocol, in much the same way that Wazuh is built on top of Kibana and ElasticSearch.
scp  root@droplet_web_server_ip:/path/to/destination/
Also, establish SSH connection into the Droplet Web Server from your Kali machine in order to remotely configure the Nginx options for serving the file, as well as testing it from the Kali UI’s Firefox browser.
Finally, transfer the  `pfsense.img`  file to the web server’s serving directory I specified in the Nginx configuration to establish a direct link. Almost there!

## Linode pfSense instance
From here, browse back to the Linode instance from your local machine and boot in Rescue mode.
The browser gives you a booting option window:
/dev/sda:  Installer
/dev/sdb:  None
/dev/sdc:  None
Then click the  ‘Reboot into Rescue Mode’  button to trigger the previously created Installer profile.
Then launch the Lish Console (Linode’s console that mimics Linux terminal).
Use curl to download the file via terminal, and use the pipe to store it directly inside of the /dev/sda partition:
curl  http://droplet-web-server-ip/pfSense-installer.img  |  dd of=/dev/sda
From the Linode instance dashboard, navigate to the Configurations tab and  Boot  the Installer configuration partition. 
After the instance is done booting, go back to your Lish Console and you’ll have pfSense image installer up on the terminal!

It gives you the most common console type, but for this guide you’ll go with xterm.
Check through most of the default configuration options.
Eventually you’ll come to an option that does not let you proceed until you check the box for “da0 QEMU QEMU HARDDISK”. This refers to the selection of the storage where the ZFS filesystem will be configured. 
da0:  a block device in the system. “da” stands for direct access storage device. da0 is the first one, in much the same way that ent0 might be your first network interface.
QEMU QEMU HARDDISK  -  the descriptor provided by the system for the storage device. QEMU likely means that it’s recognized by the QEMU emulator.
ZFS (Zettabyte File System) is designed to address limitations and challenges present in traditional filesystems, such as pooled storage and data integrity for protecting against corruption.

When the installation is done, reboot the instance from the Linode dashboard, and select the  ‘PFSENSE’  Linode configuration that you set up earlier (since you are no longer installing, you no longer need the ‘Installer’ configuration. You will only be using the PFSENSE configuration starting now).

Great!  pfSense is now booting for the first time. So much effort and trial-and-error with so many different failing methods to get this to happen on an m1 processor.

Now let’s walk through a few configuration options on the screen. 
Should VLAN be set up now?  no
Enter the WAN interface name or ‘a’ for auto-detection (vtnet0 or a):  a
When setting up a network with pfSense, it’s necessary to designate interfaces for different network segments. 
This WAN interface is the connection that links your local network to the wider internet (connects directly to your ISP).

Enter the WAN interface name or ‘a’ for auto-detection (vtnet0 or a):  vtnet0
Enter the LAN interface name or 'a' for auto-detection 
NOTE: this enables full Firewalling/NAT mode.
( a or nothing if finished):  Enter (nothing)
The interfaces will be assigned as follows:
WAN  -> vtnet0
Do you want to proceed [y|n]? y
Config is finished. You can now visit the Linode instance IP address in your Chrome browser’s bar.
It warns you that the connection is not private, but you know this is your trusted instance, so click on the ‘Advanced’ button on the page, and proceed anyway.

You now have access to the pfSense Login page. Default credentials are:
Username: admin
Password: pfsense




